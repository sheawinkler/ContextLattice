# Outreach Templates (2026-01-25)

## Cold-ish intro (platform teams)
Subject: Quick question about long-context costs

Hi {{name}},

I’m working on a private memory layer that cuts long-context spend and truncation failures for agent workflows. It installs locally, and we measure before/after token savings.

We’re running short paid pilots (2–4 weeks) to baseline token usage, deploy memMCP, and deliver a simple ROI report. Open to a 20-minute call this week?

Thanks,
{{sender}}

## Vibecoder/community post
“Fix the context problem plaguing vibecoders everywhere.”

Built a local-first memory service that gives agents persistent context over MCP. Free OSS core, quick local install, and your data stays private. Try it and tell me what breaks.

## Enterprise intro
Subject: Private context for AI agents (quick POC)

Hi {{name}},

We help teams keep AI context private (BYOK, audit logs, retention) while reducing long-context costs. We can run a short POC to measure baseline spend and show savings.

If that’s useful, I can share details.
